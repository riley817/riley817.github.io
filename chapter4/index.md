# 가상 면접 사례로 배우는 대규모 시스템 설계 기초 Study [4장] 처리율 제한 장치의 설계


{{< admonition type=tip title="Note" open=true >}}
팀 내에서 진행하는 Study 정리 입니다.
{{< /admonition >}} 

# 함께 논의 하고 싶은 주제
---
- 우리 서비스의 경우도 사용자 인증을 위해 여러 MSA 서버에서 하나의 인증 서비스를 의존하고 있다. 이러한 처리율 제한을 위한 미들웨어를 도입해도 좋을 것 같다.
- 우리 서비스에 현재 인프라적으로는 어떤것들을 제한하고 있을까? 깊게 물어본적이 없는 것다... (반성)

- 토큰 버킷 알고리즘에서 IP 주소별로 처리율 제한이 필요하면 IP 주소마다 버킷을 하나씩 할당해야한다.
  - 그럼 버킷이 엄청많아지는 것 아닌가?



# 요약
---

## 처리율 제한 장치 `rate limiter`
- 클라이언트 또는 서비스가 보내는 트래픽 처리율`rate`을 제어하기 위한 장치
- API 요청 횟수가 제한 장치에 정의된 임계치`threadhold`를 넘어서면 추가로 도달한 모든 호출은 처리가 중단`block`된다.

### API 처리율 제한 장치를 두면 좋은점
- **DoS(Denial of Service)** 공격에 의한 자원 고갈`resource starvation`을 방지
- 비용을 절감 : 과금이 횟수에 따라 이루어진다면, 그 횟수를 제한할 수 있어야 비용을 절감
- 서버의 과부하를 막는다

---
## 문제 이해 및 설계 범위 확정
- 어떤 종류의 처리율 제한 장치를 설계해야 하는가? 클라이언트 측 혹은 서버 측 제한 장치인가?
- 어떤 기준(IP, 사용자 ID)으로 API 호출을 제어해야 하는가?
- 시스템의 규모는 어떠한가
- 분산 환경에서도 동작하는가
- 독립된 서비스? 애플리케이션 코드에 포함될 수 있는가?
- 사용자에게 제한 장치에 대한 알림을 주어야 하는가

### 요구사항
- 설정된 처리율을 초과하는 요청은 정확하게 제한해야한다.
- 낮은 응답시간 : 이 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어서는 안된다.
- 가능한 한 적은 메모리를 사용
- 분산형 처리율 제한 `distributed rate limiting` : 하나의 처리율 제한 장치를 여러 서버나 프로세스에 공유할 수 있어야 한다.
- 예외처리 : 요청이 제한되었을 때 그 사실을 사용자에게 분명하게 보여주어야 한다.
- 높은 결함 감내성 `fault tolerance` : 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안 된다. 

## 개략적 설계안 제시 및 동의 구하기

### 처리율 제한장치의 위치
- 클라이언트 요청은 쉽게 위변조가 가능하고 구현을 통제하는 것도 어려울 수 있다.
- **처리율 제한 장치를 API 서버에 두는 대신 처리율 제한 미들웨어`middleware`를 만들어 통제한다.**
- 클라우드 마이크로서비스의 경우, API 게이트웨이`gateway`라 불리는 컴포넌트에 보통 구현
- **회사의 현재 기술 스택`technology stack`이나 엔지니어링 인력, 우선순위, 목표에 따라 처리율 제한 장치는 달라질 수 있다.**

{{< admonition type=note title="API 게이트 웨이" open=true >}}

API 게이트웨이는 처리율 제한, SSL 종단`termination`, 사용자 인증`authentication` IP 허용 목록`whitelist` 관리 등을 지원하는 완전 위탁관리형 서비스 `fully managed`이다. 
{{< /admonition >}} 

#### 처리율 제한장치 적용을 위한 지침
- 기술 스택 점검 고려 하기 : 현재 사용하는 프로그래밍 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인하기
- 알맞은 처리율 제한 알고리즘 선택 하기
- 이미 API 게이트웨이를 사용한다면 게이트웨이에 포함시켜야 할 수도 있다.
- 상용 API 게이트 웨이를 쓰는 것이 바람직 할 수도 

### 처리율 제한 알고리즘
- 토큰 버킷`token bucket`
- 누출 버킷`leaky bucket`
- 고정 윈도 카운터`fixed window counter`
- 이동 윈도 로그`sliding window log`
- 이동 윈도 카운터`sliding window counter`

#### 토큰 버킷 알고리즘
- 처리율 제한에 폭넓게 이용되고 있음
- 간단하고 알고리즘에 대한 세간의 이해도도 높음 


##### 토큰 버킷 알고리즘의 동작 원리
1. 토큰 버킷은 지정된 용량을 갖는 컨테이너이며 사전에 설정된 양의 토큰 공급기`refiller`에 의해 토큰이 주기적으로 채워진다. 버킷이 가득차면 토큰은 버려진다.`overflow`
2. 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사
  - 충분한 토큰이 있는 경우 : 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달
  - 충분한 토큰이 없는 경우 : 해당 요청은 버러짐`dropped`
  
##### 인자 
- **버킷 크기** : 버킷에 담을 수 있는 토큰의 최대 개수
- **토큰 공급률`refill rate`**: 초당 몇 개의 토큰이 버킷에 공급되는가 

##### 사용 사례
- 통상적으로 API 엔드포인트마다 별도의 버킷을 둔다.
- IP 주소별로 처리율 제한이 필요하면 IP 주소마다 버킷을 하나씩 할 당해야한다.

###### 장점
- 구현이 쉽다
- 메모리 사용 측면에서 효율적
- 짧은 시간에 트래픽`burst of traffic`도 처리 가능

###### 단점
- 버킷 크기와 토큰 공급률의 인자를 적절하게 튜닝하는 것이 까다로움

